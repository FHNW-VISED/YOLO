{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from tqdm import tqdm\n",
    "from yolo import Config, PostProcess, create_converter, create_model\n",
    "from yolo.tools.loss_functions import create_loss_function\n",
    "from yolo.utils.model_utils import get_device, get_mask_preds\n",
    "\n",
    "from ifc_dl.conf.augmentations import get_transform_fn\n",
    "\n",
    "# from ifc_dl.data.mock_coco_dataset import MockCocoDataModule\n",
    "from ifc_dl.data.anthony_dataset import AnthonyDataModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aaa4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\"/Users/simone.bonato/Desktop/ecolution/ecolution-floorplan-seg/\")\n",
    "IMAGE_SIZE = (256, 256)\n",
    "AUGS = {\n",
    "    \"resize\": {\n",
    "        \"params\": {\"height\": IMAGE_SIZE[0], \"width\": IMAGE_SIZE[1], \"interpolation\": 3},\n",
    "        \"all_datasets\": True,\n",
    "    },\n",
    "    \"horizontal_flip\": {\"params\": {\"p\": 0.5}},\n",
    "}\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "CONFIG_PATH = \"../YOLO/yolo/config\"\n",
    "CONFIG_NAME = \"config-seg\"\n",
    "CLASS_NUM = 2\n",
    "MODEL_WEIGHTS = BASE_PATH / \"submodules/YOLO/weights/v9-c.pt\"\n",
    "\n",
    "SAVE_MODEL_PATH = BASE_PATH / \"submodules/YOLO/weights/new_weights.pt\"\n",
    "MASK_LOSS_IMG_PATH = BASE_PATH / \"submodules/YOLO/weights/mask_loss.png\"\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set project root so modules are found correctly\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "transforms, val_transform = get_transform_fn(AUGS)\n",
    "datamodule = AnthonyDataModule(\n",
    "    BASE_PATH / \"data/anthony\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    transforms=transforms,\n",
    "    val_transforms=val_transform,\n",
    ")\n",
    "datamodule.setup()\n",
    "# train_dl = datamodule.train_dataloader()\n",
    "train_dl = datamodule.val_dataloader()\n",
    "\n",
    "\n",
    "def convert_y_for_yolo(y):\n",
    "    \"\"\"\n",
    "    Convert a list of target dictionaries to the YOLO-specific format.\n",
    "\n",
    "    Args:\n",
    "        y (list): A batch of target dictionaries containing \"labels\", \"boxes\", and \"masks\".\n",
    "\n",
    "    Returns:\n",
    "        y_yolo (Tensor): Tensor with shape (batch_size, max_annotations, 5)\n",
    "                         where boxes are formatted for YOLO.\n",
    "        y_masks (Tensor): Tensor with the down-binary masks.\n",
    "    \"\"\"\n",
    "    batch_size = len(y)\n",
    "    max_annotations = max(len(sample[\"labels\"]) for sample in y)\n",
    "    mask_shape = y[0][\"masks\"].shape[-2:]\n",
    "    y_yolo = torch.ones((batch_size, max_annotations, 5)) * -1\n",
    "    y_masks = torch.ones((batch_size, max_annotations, *mask_shape)) * -1\n",
    "\n",
    "    for i, sample in enumerate(y):\n",
    "        for j, (label, box, mask) in enumerate(\n",
    "            zip(sample[\"labels\"], sample[\"boxes\"], sample[\"masks\"])\n",
    "        ):\n",
    "            y_yolo[i, j, 0] = label\n",
    "            y_yolo[i, j, 1:] = box\n",
    "            y_masks[i, j] = (mask > 0).float()\n",
    "    return y_yolo, y_masks\n",
    "\n",
    "\n",
    "with initialize(config_path=CONFIG_PATH, version_base=None, job_name=\"notebook_job\"):\n",
    "    cfg: Config = compose(config_name=CONFIG_NAME)\n",
    "\n",
    "# for k in cfg.task.loss.objective:\n",
    "#     cfg.task.loss.objective[k] = cfg.task.loss.objective[k] if k != \"LincombMaskLoss\" else 10\n",
    "\n",
    "model = create_model(cfg.model, class_num=CLASS_NUM, weight_path=MODEL_WEIGHTS)\n",
    "model = model.to(device)\n",
    "\n",
    "converter = create_converter(\n",
    "    cfg.model.name, model, cfg.model.anchor, IMAGE_SIZE, device\n",
    ")\n",
    "\n",
    "# Optionally set up post-processing if NMS is used\n",
    "post_process = None\n",
    "if cfg.task.get(\"nms\"):\n",
    "    post_process = PostProcess(converter, cfg.task.nms)\n",
    "\n",
    "cfg.dataset.class_num = CLASS_NUM\n",
    "loss_fn = create_loss_function(cfg, converter)\n",
    "\n",
    "model.train()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feabf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_losses = []\n",
    "grad_norms = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Get a single batch\n",
    "single_batch = next(iter(train_dl))\n",
    "x, y = single_batch\n",
    "\n",
    "# Fix input channels: repeat channels if a sample has only one channel\n",
    "x = list(x)\n",
    "for i in range(len(x)):\n",
    "    if x[i].shape[0] == 1:\n",
    "        x[i] = x[i].repeat(3, 1, 1)\n",
    "x = torch.stack(x).to(device)\n",
    "\n",
    "# Convert target annotations to YOLO format\n",
    "y_yolo, y_masks = convert_y_for_yolo(y)\n",
    "y_yolo = y_yolo.to(device)\n",
    "y_masks = y_masks.to(device)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Forward pass\n",
    "    out = model(x)\n",
    "    det_logits, seg_logits = out[\"Main\"]\n",
    "    det_logits_aux, seg_logits_aux = out[\"AUX\"]\n",
    "\n",
    "    det_preds = converter(det_logits)\n",
    "    det_preds_aux = converter(det_logits_aux)\n",
    "\n",
    "    # Compute loss\n",
    "    loss_value, loss_dict = loss_fn(\n",
    "        det_preds_aux,\n",
    "        det_preds,\n",
    "        deepcopy(y_yolo),\n",
    "        y_masks,\n",
    "        seg_logits_aux,\n",
    "        seg_logits,\n",
    "    )\n",
    "\n",
    "    # Backpropagation and optimization step\n",
    "    optim.zero_grad()\n",
    "    loss_value.backward()\n",
    "\n",
    "    # Monitor gradient norms\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm**0.5\n",
    "    grad_norms.append(total_norm)\n",
    "\n",
    "    optim.step()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {loss_value.item()}, Grad Norm: {total_norm}\"\n",
    "    )\n",
    "    mask_losses.append(loss_dict[\"Loss/LincombMaskLoss\"])\n",
    "\n",
    "# Save model and plot\n",
    "torch.save(model.state_dict(), SAVE_MODEL_PATH)\n",
    "plt.figure()\n",
    "plt.plot(mask_losses, label=\"Mask Loss\")\n",
    "# plt.plot(grad_norms, label=\"Grad Norm\")\n",
    "plt.legend()\n",
    "plt.title(\"Mask Loss and Gradient Norm Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    tqdm_loop = tqdm(enumerate(train_dl), total=len(train_dl), desc=\"Training\")\n",
    "    mask_losses_epoch = []\n",
    "    for batch_idx, (x, y) in tqdm_loop:\n",
    "        # Fix input channels: repeat channels if a sample has only one channel\n",
    "        x = list(x)\n",
    "        for i in range(len(x)):\n",
    "            if x[i].shape[0] == 1:\n",
    "                x[i] = x[i].repeat(3, 1, 1)\n",
    "        x = torch.stack(x).to(device)\n",
    "\n",
    "        # Convert target annotations to YOLO format\n",
    "        y_yolo, y_masks = convert_y_for_yolo(y)\n",
    "        y_yolo = y_yolo.to(device)\n",
    "        y_masks = y_masks.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(x)\n",
    "        det_logits, seg_logits = out[\"Main\"]\n",
    "        det_logits_aux, seg_logits_aux = out[\"AUX\"]\n",
    "\n",
    "        det_preds = converter(det_logits)\n",
    "        det_preds_aux = converter(det_logits_aux)\n",
    "\n",
    "        # Compute loss\n",
    "        loss_value, loss_dict = loss_fn(\n",
    "            det_preds_aux,\n",
    "            det_preds,\n",
    "            deepcopy(y_yolo),\n",
    "            y_masks,\n",
    "            seg_logits_aux,\n",
    "            seg_logits,\n",
    "        )\n",
    "        tqdm_loop.set_description(\n",
    "            f\"Epoch: {epoch + 1} | Batch {batch_idx + 1}/{len(train_dl)} | {loss_dict=}\"\n",
    "        )\n",
    "\n",
    "        # Backpropagation and optimization step\n",
    "        optim.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optim.step()\n",
    "\n",
    "        mask_losses_epoch.append(loss_dict[\"Loss/LincombMaskLoss\"])\n",
    "\n",
    "        if batch_idx == 3:\n",
    "            break\n",
    "\n",
    "    mask_losses.append(torch.mean(torch.tensor(mask_losses_epoch)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a7af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x)\n",
    "det_logits, seg_logits = pred[\"Main\"]\n",
    "det_logits_aux, seg_logits_aux = pred[\"AUX\"]\n",
    "\n",
    "det_preds = converter(det_logits)\n",
    "det_preds_aux = converter(det_logits_aux)\n",
    "\n",
    "# Get the mask predictions\n",
    "mask_preds = get_mask_preds(seg_logits, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "nms_config = {\n",
    "    \"min_confidence\": 0.0001,\n",
    "    \"min_iou\": 0.05,\n",
    "    \"max_bbox\": 300,\n",
    "}\n",
    "nms_config = OmegaConf.create(nms_config)\n",
    "post_proccess = PostProcess(converter, nms_config)\n",
    "\n",
    "boxes, seg = post_proccess(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e338fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 1\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(y_masks[img_idx].sum(0).cpu().numpy())\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(seg[img_idx].sum(0).cpu().numpy() > 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d87b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(mask_losses, label=\"Mask Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Mask Loss and Gradient Norm Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
