{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61dc186",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from yolo import Config, PostProcess, create_converter, create_model, draw_bboxes\n",
    "from yolo.utils.model_utils import get_device\n",
    "from yolo.tools.loss_functions import create_loss_function\n",
    "\n",
    "from ifc_dl.conf.augmentations import get_transform_fn\n",
    "from ifc_dl.data.mock_coco_dataset import MockCocoDataModule\n",
    "from ifc_dl.utils import plot_instance_segmentation_data\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (512, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29787e0",
   "metadata": {},
   "source": [
    "# Load the datamodule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = {\n",
    "    \"resize\": {\n",
    "        \"params\": {\"height\": image_size[0], \"width\": image_size[1], \"interpolation\": 3},\n",
    "        \"all_datasets\": True,\n",
    "    },\n",
    "    \"horizontal_flip\": {\"params\": {\"p\": 0.5}},\n",
    "}\n",
    "\n",
    "transforms, val_transform = get_transform_fn(augs)\n",
    "datamodule = MockCocoDataModule(batch_size=2, transforms=transforms, val_transform=val_transform)\n",
    "datamodule.setup()\n",
    "train_dl = datamodule.train_dataloader()\n",
    "\n",
    "x, y = next(iter(train_dl))\n",
    "x = torch.stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd73439",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_y_for_yolo(y):\n",
    "    #  convert y to the format that yolo likes \n",
    "    max_annotations = max(len(y_[\"labels\"]) for y_ in y)\n",
    "\n",
    "    y_yolo = torch.ones((x.shape[0], max_annotations, 5)) * -1\n",
    "    y_masks = torch.ones((x.shape[0], max_annotations, *y[0][\"masks\"].shape[-2:])) * -1\n",
    "\n",
    "    for i_y, y_ in enumerate(y):\n",
    "        for i_instance, (label, box, mask) in enumerate(zip(y_[\"labels\"], y_[\"boxes\"], y_[\"masks\"])):\n",
    "            y_yolo[i_y, i_instance, 0] = label\n",
    "            y_yolo[i_y, i_instance, 1:] = box\n",
    "            \n",
    "            y_masks[i_y, i_instance] = (mask > 0).to(int)\n",
    "            \n",
    "    return y_yolo, y_masks\n",
    "\n",
    "y_yolo, y_masks = convert_y_for_yolo(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35bcd71",
   "metadata": {},
   "source": [
    "# Load the YOLO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "CONFIG_PATH = \"../YOLO/yolo/config\"\n",
    "CONFIG_NAME = \"config-seg\"\n",
    "CLASS_NUM = 91\n",
    "\n",
    "with initialize(config_path=CONFIG_PATH, version_base=None, job_name=\"notebook_job\"):\n",
    "    cfg: Config = compose(config_name=CONFIG_NAME)\n",
    "\n",
    "device, _ = get_device(cfg.device)\n",
    "model = create_model(\n",
    "    cfg.model,\n",
    "    class_num=CLASS_NUM,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "converter = create_converter(\n",
    "    cfg.model.name, model, cfg.model.anchor, image_size, device\n",
    ")\n",
    "\n",
    "post_proccess = None\n",
    "if cfg.task.get(\"nms\"):\n",
    "    post_proccess = PostProcess(converter, cfg.task.nms)\n",
    "\n",
    "cfg.dataset.class_num = CLASS_NUM\n",
    "loss = create_loss_function(cfg, converter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc9a3c",
   "metadata": {},
   "source": [
    "# Forward pass and segmentation masks predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "out = model(x)\n",
    "\n",
    "det_logits, seg_logits = out[\"Main\"]\n",
    "det_logits_aux, seg_logits_aux = out[\"AUX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4264607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: mask coeffs and last one is the mask prototype\n",
    "print(\"--- segmentation head ---\")\n",
    "for l in seg_logits:\n",
    "    print(l.shape)\n",
    "\n",
    "print(\"\\n--- detection head ---\")\n",
    "# for each resolution we have: class, object, bbox, mask coefficients \n",
    "for l in det_logits:\n",
    "    for det_l in l: \n",
    "        print(det_l.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256efc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "def get_mask_preds(seg_logits, sigmoid=False):\n",
    "    # linear combination of the coefficients with the mask predictions\n",
    "    coeffs, proto = seg_logits[:-1], seg_logits[-1]\n",
    "    \n",
    "    reshaped_coeffs = []\n",
    "    for coeff in coeffs:\n",
    "        reshaped_coeff = rearrange(coeff, \"B M w h -> B (w h) M\")\n",
    "        reshaped_coeffs.append(reshaped_coeff)\n",
    "\n",
    "    pred_coeffs = torch.concat(reshaped_coeffs, dim=1)\n",
    "\n",
    "    pred_masks_logits = torch.einsum(\"bnm, bmhw -> bnhw\", pred_coeffs, proto)\n",
    "    if not sigmoid:\n",
    "        return pred_masks_logits\n",
    "    \n",
    "    return torch.sigmoid(pred_masks_logits)    \n",
    "\n",
    "\n",
    "seg_preds = get_mask_preds(seg_logits)\n",
    "seg_preds_aux = get_mask_preds(seg_logits_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_preds = converter(det_logits)\n",
    "det_preds_aux = converter(det_logits_aux)\n",
    "\n",
    "for p in det_preds:\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832e2e3",
   "metadata": {},
   "source": [
    "# Loss computation\n",
    "\n",
    "Make sure that the normal loss can still be computed normally, then add the masks to it.\n",
    "\n",
    "## TODO\n",
    "- [] Add the masks to the \n",
    "- [] Add to the loss computation the possibility to have the masks\n",
    "- [] Compute the BCE with the target masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c17021",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_preds[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97361f59",
   "metadata": {},
   "source": [
    "what do I need to pass as input to the loss function for the segmentation part?\n",
    "- coefficients for the prototypes \n",
    "- target masks [B, max_instances_in_gt, H, W]\n",
    "- pred masks (both aux and main) [B, all_anchor_preds, H', W']\n",
    "\n",
    "Then I will need to use: \n",
    "- the GT boxes (already in the main loss)\n",
    "\n",
    "To add as well, optionally:\n",
    "- the coeff diversity loss \n",
    "- the foreground and backgroung weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "loss_value, loss_dict = loss(\n",
    "    det_preds_aux, det_preds, deepcopy(y_yolo), y_masks, seg_logits_aux, seg_logits\n",
    ")\n",
    "\n",
    "\n",
    "loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377335ef",
   "metadata": {},
   "source": [
    "## Training loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea367678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 3\n",
    "\n",
    "datamodule = MockCocoDataModule(batch_size=BATCH_SIZE, transforms=transforms, val_transform=val_transform)\n",
    "datamodule.setup()\n",
    "train_dl = datamodule.train_dataloader()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "tqdm_loop = tqdm(enumerate(train_dl))\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (x, y) in tqdm_loop:\n",
    "        x = torch.stack(x)\n",
    "        y_yolo, y_masks = convert_y_for_yolo(y)\n",
    "        \n",
    "        out = model(x)\n",
    "\n",
    "        det_logits, seg_logits = out[\"Main\"]\n",
    "        det_logits_aux, seg_logits_aux = out[\"AUX\"]\n",
    "        \n",
    "        det_preds = converter(det_logits)\n",
    "        det_preds_aux = converter(det_logits_aux)\n",
    "        \n",
    "        loss_value, loss_dict = loss(\n",
    "            det_preds_aux, det_preds, deepcopy(y_yolo), y_masks, seg_logits_aux, seg_logits\n",
    "        )\n",
    "        tqdm_loop.set_description(f\"Epoch: {epoch+1} | Batch {batch_idx+1} / {len(train_dl)} | losses {loss_dict=}\")\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optim.step()\n",
    "    \n",
    "\n",
    "# TODO: add the optim and the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31281c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_logits, seg_logits = out[\"Main\"]\n",
    "det_logits_aux, seg_logits_aux = out[\"AUX\"]\n",
    "\n",
    "det_preds = converter(det_logits)\n",
    "det_preds_aux = converter(det_logits_aux)\n",
    "\n",
    "loss_value, loss_dict = loss(\n",
    "    det_preds_aux, det_preds, deepcopy(y_yolo), y_masks, seg_logits_aux, seg_logits\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
