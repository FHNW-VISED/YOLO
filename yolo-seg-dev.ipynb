{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61dc186",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from yolo import Config, PostProcess, create_converter, create_model\n",
    "from yolo.utils.model_utils import get_device, get_mask_preds\n",
    "from yolo.tools.loss_functions import create_loss_function\n",
    "\n",
    "from ifc_dl.conf.augmentations import get_transform_fn\n",
    "from ifc_dl.data.mock_coco_dataset import MockCocoDataModule\n",
    "from ifc_dl.utils import plot_instance_segmentation_data\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (512, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29787e0",
   "metadata": {},
   "source": [
    "# Load the datamodule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = {\n",
    "    \"resize\": {\n",
    "        \"params\": {\"height\": image_size[0], \"width\": image_size[1], \"interpolation\": 3},\n",
    "        \"all_datasets\": True,\n",
    "    },\n",
    "    \"horizontal_flip\": {\"params\": {\"p\": 0.5}},\n",
    "}\n",
    "\n",
    "transforms, val_transform = get_transform_fn(augs)\n",
    "datamodule = MockCocoDataModule(batch_size=2, transforms=transforms, val_transform=val_transform)\n",
    "datamodule.setup()\n",
    "train_dl = datamodule.train_dataloader()\n",
    "\n",
    "x, y = next(iter(train_dl))\n",
    "x = torch.stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd73439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_for_yolo(y):\n",
    "    #  convert y to the format that yolo likes \n",
    "    max_annotations = max(len(y_[\"labels\"]) for y_ in y)\n",
    "\n",
    "    y_yolo = torch.ones((x.shape[0], max_annotations, 5)) * -1\n",
    "    y_masks = torch.ones((x.shape[0], max_annotations, *y[0][\"masks\"].shape[-2:])) * -1\n",
    "\n",
    "    for i_y, y_ in enumerate(y):\n",
    "        for i_instance, (label, box, mask) in enumerate(zip(y_[\"labels\"], y_[\"boxes\"], y_[\"masks\"])):\n",
    "            y_yolo[i_y, i_instance, 0] = label\n",
    "            y_yolo[i_y, i_instance, 1:] = box\n",
    "            \n",
    "            y_masks[i_y, i_instance] = (mask > 0).to(int)\n",
    "            \n",
    "    return y_yolo, y_masks\n",
    "\n",
    "y_yolo, y_masks = convert_y_for_yolo(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35bcd71",
   "metadata": {},
   "source": [
    "# Load the YOLO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "CONFIG_PATH = \"../YOLO/yolo/config\"\n",
    "CONFIG_NAME = \"config-seg\"\n",
    "CLASS_NUM = 91\n",
    "\n",
    "# can also be True, False\n",
    "# if you put the path to another model weights, it will load all the weights for the common layers between the two models\n",
    "MODEL_WEIGHTS = \"/Users/simone.bonato/Desktop/ecolution/ecolution-floorplan-seg/submodules/YOLO/weights/v9-c.pt\"\n",
    "\n",
    "with initialize(config_path=CONFIG_PATH, version_base=None, job_name=\"notebook_job\"):\n",
    "    cfg: Config = compose(config_name=CONFIG_NAME)\n",
    "\n",
    "device, _ = get_device(cfg.device)\n",
    "model = create_model(\n",
    "    cfg.model,\n",
    "    class_num=CLASS_NUM,\n",
    "    weight_path=MODEL_WEIGHTS\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "converter = create_converter(\n",
    "    cfg.model.name, model, cfg.model.anchor, image_size, device\n",
    ")\n",
    "\n",
    "post_proccess = None\n",
    "if cfg.task.get(\"nms\"):\n",
    "    post_proccess = PostProcess(converter, cfg.task.nms)\n",
    "\n",
    "cfg.dataset.class_num = CLASS_NUM\n",
    "loss = create_loss_function(cfg, converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba235040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weight from the training\n",
    "# w = torch.load(\"/Users/simone.bonato/Desktop/ecolution/ecolution-floorplan-seg/submodules/YOLO/model_seg_w.pth\", map_location=device)\n",
    "# model.load_state_dict(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc9a3c",
   "metadata": {},
   "source": [
    "# Forward pass and segmentation masks predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "# model.eval()\n",
    "\n",
    "out = model(x)\n",
    "\n",
    "det_logits, seg_logits = out[\"Main\"]\n",
    "det_logits_aux, seg_logits_aux = out[\"AUX\"]\n",
    "\n",
    "seg_preds = get_mask_preds(seg_logits, sigmoid=True)\n",
    "seg_preds_aux = get_mask_preds(seg_logits_aux, sigmoid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4264607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: mask coeffs and last one is the mask prototype\n",
    "print(\"--- segmentation head ---\")\n",
    "for l in seg_logits:\n",
    "    print(l.shape)\n",
    "\n",
    "print(\"\\n--- detection head ---\")\n",
    "# for each resolution we have: class, object, bbox, mask coefficients \n",
    "for l in det_logits:\n",
    "    for det_l in l: \n",
    "        print(det_l.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_preds = converter(det_logits)\n",
    "det_preds_aux = converter(det_logits_aux)\n",
    "\n",
    "for p in det_preds:\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_seg_logits = []\n",
    "\n",
    "# b = 2\n",
    "# c = 32\n",
    "# hw = [64, 32, 16, 128]\n",
    "\n",
    "# for i in range(len(hw)):\n",
    "#     fake_seg_logits.append(torch.randn(b, c, hw[i], hw[i]))\n",
    "\n",
    "# out = model(x)\n",
    "# out[\"Main\"] = (out[\"Main\"], fake_seg_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "nms_config = {\n",
    "    \"min_confidence\": 0.1,\n",
    "    \"min_iou\": 0.,\n",
    "    \"max_bbox\": 300,\n",
    "}\n",
    "nms_config = OmegaConf.create(nms_config)\n",
    "post_proccess = PostProcess(converter, nms_config)\n",
    "\n",
    "# TODO: make sure that when the masks are upscaled by the converter!\n",
    "pred = post_proccess(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9058c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pred_seg = pred\n",
    "\n",
    "for b in pred_seg:\n",
    "    for p in b:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.imshow(p.cpu().numpy())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832e2e3",
   "metadata": {},
   "source": [
    "# Loss computation\n",
    "\n",
    "Make sure that the normal loss can still be computed normally, then add the masks to it.\n",
    "\n",
    "## TODO\n",
    "- [] Add the masks to the \n",
    "- [] Add to the loss computation the possibility to have the masks\n",
    "- [] Compute the BCE with the target masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c17021",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_preds[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97361f59",
   "metadata": {},
   "source": [
    "what do I need to pass as input to the loss function for the segmentation part?\n",
    "- coefficients for the prototypes \n",
    "- target masks [B, max_instances_in_gt, H, W]\n",
    "- pred masks (both aux and main) [B, all_anchor_preds, H', W']\n",
    "\n",
    "Then I will need to use: \n",
    "- the GT boxes (already in the main loss)\n",
    "\n",
    "To add as well, optionally:\n",
    "- the coeff diversity loss \n",
    "- the foreground and backgroung weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "loss_value, loss_dict = loss(\n",
    "    det_preds_aux, det_preds, deepcopy(y_yolo), y_masks, seg_logits_aux, seg_logits\n",
    ")\n",
    "\n",
    "\n",
    "loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377335ef",
   "metadata": {},
   "source": [
    "## Training loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea367678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 3\n",
    "\n",
    "datamodule = MockCocoDataModule(batch_size=BATCH_SIZE, transforms=transforms, val_transform=val_transform)\n",
    "datamodule.setup()\n",
    "train_dl = datamodule.train_dataloader()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    tqdm_loop = tqdm(enumerate(train_dl), total=len(train_dl), desc=\"Training\")\n",
    "    for batch_idx, (x, y) in tqdm_loop:\n",
    "        \n",
    "        # ugly fix!\n",
    "        x = list(x)\n",
    "        for i in range(len(x)):\n",
    "            if x[i].shape[0] ==1:\n",
    "                x[i] = x[i].repeat(3, 1, 1)\n",
    "        \n",
    "        x = torch.stack(x).to(device)\n",
    "        y_yolo, y_masks = convert_y_for_yolo(y)\n",
    "        \n",
    "        y_yolo = y_yolo.to(device)\n",
    "        y_masks = y_masks.to(device)\n",
    "        \n",
    "        out = model(x)\n",
    "\n",
    "        det_logits, seg_logits = out[\"Main\"]\n",
    "        det_logits_aux, seg_logits_aux = out[\"AUX\"]\n",
    "        \n",
    "        det_preds = converter(det_logits)\n",
    "        det_preds_aux = converter(det_logits_aux)\n",
    "        \n",
    "        loss_value, loss_dict = loss(\n",
    "            det_preds_aux, det_preds, deepcopy(y_yolo), y_masks, seg_logits_aux, seg_logits\n",
    "        )\n",
    "        tqdm_loop.set_description(f\"Epoch: {epoch+1} | Batch {batch_idx+1} / {len(train_dl)} | losses {loss_dict=}\")\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pytest_path = \"/Users/simone.bonato/Desktop/ecolution/ecolution-floorplan-seg/submodules/YOLO/tests/test_tools/test_loss_functions.py\"\n",
    "\n",
    "import pytest\n",
    "\n",
    "pytest_args = [\n",
    "    pytest_path,\n",
    "    \"-k\",\n",
    "    \"test_loss_function\",\n",
    "    \"-v\",\n",
    "    \"--tb=short\",\n",
    "]\n",
    "pytest.main(pytest_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
